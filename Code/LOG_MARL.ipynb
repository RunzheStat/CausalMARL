{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "2. try temporal; time_dependent\n",
    "\n",
    "5. tomorrow's API\n",
    "8. draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Later\n",
    "3. very fast? why slow?\n",
    "1. NN paras\n",
    "11. MSE, STD, Bias [result loss]\n",
    "\n",
    "2. why IS和DR相比variance差不多，我觉得有点奇怪 -CV?\n",
    "1. output: convenient for R\n",
    "1. no_MF so large? why?\n",
    "3. 使得overfitting? 把biad 弄下去？\n",
    "1. 还是depends on the pattern\n",
    "1. why variance 差别这么小?\n",
    "4. 看之前的结果 理解trend\n",
    "5. simple 会怎样？\n",
    "6. less bias, large variance?\n",
    "1. NN random number\n",
    "\n",
    "## TODO\n",
    "3. 整理代码 - 他的需求\n",
    "4. 汇报结果\n",
    "    1. 画图\n",
    "    2. 整理setting\n",
    "1. draft\n",
    "\n",
    "1. 96 replications, 25regions. 4 targets (maybe more) = 3 hours\n",
    "2. 7-14 = 8 settings (no clear trend?). patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "1. value estimations are all good\n",
    "2. difference estimations are all good\n",
    "3. better than IS in 1, 2\n",
    "4. better than single agent (in bias) in 1, 2\n",
    "5. better than all neigh infomation (in variance) in 1, 2\n",
    "\n",
    "\n",
    "1. ours\n",
    "2. average\n",
    "3. QV \n",
    "4. DR_no_MARL\n",
    "5. DR_no_Mean_Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "0. Mis\n",
    "    1. Size: grid, N = 5 * 5, T = 14/7 * 48\n",
    "    2. at time t, based on $O_t$ and $D_t$ which are observations  during (t-1, t], we (randomly) choose action $A_t$ which will be implemented during (t, t + 1], and observe the reward $R_t$ which is defind as the mismatch during (t, t + 1].\n",
    "1. State:\n",
    "    1. Order: $O_{l,t} \\sim Poisson(u^O_{l})$, where $u^O_{l} \\sim logN(4.6, .3)$  (mean = 104, std = 32) \n",
    "    2. Driver: \n",
    "        1. Attraction of $l$: $Att_{l,t} = exp(w_A * A_{l,t}) + w_O * (\\frac{O_{l,t}}{1 + D_{l,t}}) \\textbf{check}$\n",
    "        2. Dynamics:  $D_{l, t + 1} = \\sum_{i \\in N_l} (\\frac{Att_{l,t}}{\\sum_{j \\in N_j}Att_{j,t}}D_{i,t} )$\n",
    "        3. Computation: matrix multiplication\n",
    "    4. Mismatch: $M_{t+1,g} = 0.5 * (1-\\frac{|D_{t+1,g}-O_{t+1,g}|}{|1 + D_{t+1,g}+O_{t+1,g}|}) + 0.5 * M_{t,g}$\n",
    "4. Reward: $R_{t,g} = M_{t + 1, g}min(D_{t + 1,g}, O_{t + 1,g}) + e^R_{t,g}$ \n",
    "3. Behav policy: $A_{t,g} \\sim Bernoulli(0.5)$\n",
    "5. Target policies:  $ \\boldsymbol{\\pi}_c =  \\{\\pi_l = I_{\\{u^O_l \\ge c\\}}\\}_{l = 1}^N$\n",
    "\n",
    "\n",
    "3. Competing methods: \n",
    "    1. IS: Importance Sampling + mean-field\n",
    "    3. DR without MARL: single-agent DR \n",
    "    2. DR w/o mean-field: $R_{it}$ with all neighborhood states/actions\n",
    "    4. Naive average: value of the behaviour policy\n",
    "\n",
    "8. Report results for four target policies $\\boldsymbol{\\pi}_c$ with one order pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "1. Noise\n",
    "    1. sd_O\n",
    "    2. sd_R\n",
    "    3. sd_D\n",
    "2. spatial\n",
    "    1. w_O\n",
    "    2. w_A\n",
    "2. hyperparameters of NN and Q/V\n",
    "2. Region difference\n",
    "    1. sd_u_O\n",
    "    2. u_D = np.mean(u_O) - 2\n",
    "5. T\n",
    "6. l\n",
    "7. threshold_range\n",
    "8. pattern seed\n",
    "10. n_neigh (simple = False)\n",
    "1. Archive\n",
    "    1. mean_reversion: D_t = (D_t + u_D) / 2\n",
    "    9. p_behav\n",
    "    4. reward def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive\n",
    "2. $\\vec{D}_{t+1} = \\frac{1}{2}(\\omega_t^{-1} (\\mathbf{O}_t \\times (\\mathbf{A}_{t} + \\mathbf{I}) \\times \\mathbf{Adj}  \\times (\\mathbf{O}_t + \\mathbf{I})^{-1})  \\vec{D}_{t} + 10) + \\vec{\\epsilon}^D_{t+1}$\n",
    "3. $\\vec{D}_{t+1} = \\frac{1}{2}(\\omega_t^{-1} (\\mathbf{O}_t \\times (\\mathbf{A}_{t} + \\mathbf{I}) \\times \\mathbf{Adj}  \\times (\\mathbf{O}_t + \\mathbf{I})^{-1})  \\vec{D}_{t} + 10 * (2 - sin(t/48 * 2\\pi))) + \\vec{\\epsilon}^D_{t+1}$\n",
    "2. $O_{t,g} \\sim Poisson(10 * (2 - sin(t/48 * 2\\pi)))$ [no heterogeneity] -> mean is 20?\n",
    "2. $R_{i,t}=M_{i,t} * min(D_{i,t}, O_{i,t})+mean \\{M_{j,t} * min(D_{j,t}, O_{j,t})\\}_{j\\in N(i)}+\\epsilon_{i,t}$\n",
    "1. $A_{t,g} = a_g, a_g \\sim Bernoulli(0.5)$\n",
    "2. $M_{t+1,g} = 1-\\frac{|D_{t+1,g}-O_{t+1,g}|}{|D_{t+1,g}+O_{t+1,g}|}$\n",
    "2. $O_{t,g} \\sim Poisson(10)$\n",
    "1. $\\vec{D}_{t+1} = \\omega_t^{-1} \\mathbb{P}(((w_O * \\mathbf{O}_t + \\mathbf{I}) \\times (w_A * \\mathbf{A}_{t} +  \\mathbf{I}) \\times \\mathbf{Adj}  \\times (w_O * \\mathbf{O}_t + \\mathbf{I})^{-1})  \\vec{D}_{t} + \\vec{\\epsilon}^D_{t+1})$\n",
    "    1. $w_t$ is a normalization parameter, $\\mathbf{A}_{t}$ and $\\mathbf{O}_t$ are corresponding diagonal matries, and $\\vec{\\epsilon}^D_t \\sim (Poisson(1) - 1)$\n",
    "    2. operator $\\mathbb{P}$ is defined as $\\mathbb{P}(\\vec{D}) = (max(int(D_1),1),\\dots, max(int(D_N),1))^T$      \n",
    "1. + \\epsilon^R_{t,g}, \\epsilon^R_{t,g} \\sim N(0,sd_R)$\n",
    "1. 1. $A_{t,g} = I_{\\{u^O_l \\ge \\}}$\n",
    "\n",
    "### Metrics and competing methods\n",
    "1. Ground truth: MC-based proxy\n",
    "2. Metrics: bias, std and MSE (100 replicates)\n",
    "\n",
    "2. \"Susan\": Value funcions (Susan) + mean-field"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
