{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.711, 49.099, 46.711,  0.   , 38.767, 49.099])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from _utility import * \n",
    "from weight import * \n",
    "from simu_funs import *  \n",
    "from main import *\n",
    "a = now()\n",
    "\n",
    "\n",
    "seed = 1; l = 3; T = 336;  u_D = 80; \n",
    "sd_D = 3; sd_R = 0; sd_O = 1; CV_QV = False; \n",
    "dim_S_plus_Ts = 3 + 3;  w_A = 1; w_O = .05; penalty = [[1], [1]]; penalty_NMF = [[1], [1]]; \n",
    "n_layer = 2; w_hidden = 10; Learning_rate = 1e-4;  \n",
    "batch_size = 64; max_iteration = 1001; epsilon = 1e-3; \n",
    "with_MF = True; with_NO_MARL = False; with_IS  = True; inner_parallel = False\n",
    "\n",
    "\n",
    "npseed(2)\n",
    "u_O = rnorm(100, 25, l**2)\n",
    "    \n",
    "def t_func(t):\n",
    "    return int(t % 48)\n",
    "\n",
    "adaptive_action_list = []\n",
    "adaptive_tp_dictionary = []\n",
    "for region_index in range(9):\n",
    "    region_action=[]\n",
    "    for time_index in range(336):\n",
    "        if(time_index%48 in [36,37,38,39,40]):\n",
    "            adaptive_action_list.append(1)\n",
    "            region_action.append(1)\n",
    "        else:\n",
    "            adaptive_action_list.append(0)\n",
    "            region_action.append(0)\n",
    "    adaptive_tp_dictionary.append(region_action)\n",
    "# print(adaptive_tp_dictionary)\n",
    "\n",
    "pi_adaptive = []\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False, fixed_policy_i = adaptive_tp_dictionary[i]):\n",
    "        t = int(s[3])\n",
    "        if random_choose:\n",
    "            return fixed_policy_i[t]\n",
    "        else:\n",
    "            return int(a == fixed_policy_i[t])\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive\n",
    "    \n",
    "npseed(seed)\n",
    "N = l ** 2\n",
    "def behav(s, a):\n",
    "    return 0.5\n",
    "behav = list(itertools.repeat(behav, N))\n",
    "\n",
    "def Ts(S_neigh):\n",
    "    return np.mean(S_neigh, 0)\n",
    "def Ta(A_neigh):\n",
    "    return Ta_disc(np.mean(A_neigh, 0))\n",
    "\n",
    "# observed data following behav\n",
    "data, adj_mat, details = DG_once(seed = seed, l = l, T = T, u_D = u_D, \n",
    "                                 u_O = u_O, \n",
    "                                 t_func = t_func,  \n",
    "                                 sd_D = sd_D, sd_R = sd_R, sd_O = sd_O, \n",
    "                                 w_A = w_A, w_O = w_O)\n",
    "\n",
    "# OPE\n",
    "a = now()\n",
    "value_targets = []\n",
    "count = 0\n",
    "value_estimators = V_DR(data = data, tp = target_policy, bp = behav, \n",
    "                        adj_mat = adj_mat, dim_S_plus_Ts = dim_S_plus_Ts, \n",
    "                     t_func = t_func, \n",
    "                     Ts = Ts, Ta = Ta, penalty = penalty, penalty_NMF = penalty_NMF, \n",
    "                        n_layer = n_layer, CV_QV = CV_QV, \n",
    "                    w_hidden = w_hidden, lr = Learning_rate,  \n",
    "                    batch_size = batch_size, max_iteration = max_iteration, epsilon = epsilon, \n",
    "                        with_MF = with_MF, with_NO_MARL = with_NO_MARL, with_IS = with_IS, \n",
    "                     inner_parallel = inner_parallel)\n",
    "value_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _utility import * \n",
    "from weight import * \n",
    "from simu_funs import *  \n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample input for specifying t_func and tp:\n",
    "\n",
    "### 1. tp depending on order and driver\n",
    "\n",
    "# assume s = [o, d, mismatch]\n",
    "pi_adaptive = []\n",
    "threshold = 1\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False):\n",
    "        is_reward = int(s[0] / s[1] > threshold) # when order > driver, we give subsidy\n",
    "        if random_choose:\n",
    "            return is_reward\n",
    "        else:\n",
    "            return int(a == is_reward)\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive\n",
    "\n",
    "t_func = None\n",
    "\n",
    "### 2. tp depending on location and time_of_day - option 1 \n",
    "# (RECOMMENDED) it may reduce variance with such a discretized time stamp\n",
    "\n",
    "# if you need a more complex dependecy on time and location, please modify this exmaple or let me know\n",
    "\n",
    "def t_func(t):\n",
    "    # the time state variable is an indicator for rush hours\n",
    "    return int(t % 48 in [36,37,38,39,40])\n",
    "range_transformed_time_index = [0, 1] # can be extended to more than two time slices\n",
    "\n",
    "location_give_subsidy = [0, 1, 2] # other regions will never receive subsidy\n",
    "\n",
    "# adaptive_tp_dictionary is a len-N of len-N_range_transformed_time_index of binary value indicating \n",
    "# whether or not this space-time slice should receive subsidy\n",
    "# For example: \n",
    "\n",
    "adaptive_action_list = []\n",
    "adaptive_tp_dictionary = []\n",
    "for region_index in range(9):\n",
    "    region_action=[]\n",
    "    for time_index in range_transformed_time_index:\n",
    "        if(time_index == 1 and region_index in location_give_subsidy):\n",
    "            adaptive_action_list.append(1)\n",
    "            region_action.append(1)\n",
    "        else:\n",
    "            adaptive_action_list.append(0)\n",
    "            region_action.append(0)\n",
    "    adaptive_tp_dictionary.append(region_action)\n",
    "print(adaptive_tp_dictionary)\n",
    "\n",
    "\n",
    "pi_adaptive = []\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False, fixed_policy_i = adaptive_tp_dictionary[i]): # , fixed_policy_i = adaptive_tp_dictionary[i]\n",
    "        t = int(s[3]) # already transformed by t_func\n",
    "        if random_choose:\n",
    "            return fixed_policy_i[t]\n",
    "        else:\n",
    "            return int(a == fixed_policy_i[t])\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive\n",
    "\n",
    "\n",
    "### 3. tp depending on location and time_of_day - option 2\n",
    "def t_func(t):\n",
    "    return int(t % 48)\n",
    "\n",
    "adaptive_action_list = []\n",
    "adaptive_tp_dictionary = []\n",
    "for region_index in range(9):\n",
    "    region_action=[]\n",
    "    for time_index in range(336):\n",
    "        if(time_index%48 in [36,37,38,39,40]):\n",
    "            adaptive_action_list.append(1)\n",
    "            region_action.append(1)\n",
    "        else:\n",
    "            adaptive_action_list.append(0)\n",
    "            region_action.append(0)\n",
    "    adaptive_tp_dictionary.append(region_action)\n",
    "# print(adaptive_tp_dictionary)\n",
    "\n",
    "pi_adaptive = []\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False, fixed_policy_i = adaptive_tp_dictionary[i]):\n",
    "        t = int(s[3])\n",
    "        if random_choose:\n",
    "            return fixed_policy_i[t]\n",
    "        else:\n",
    "            return int(a == fixed_policy_i[t])\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive\n",
    "\n",
    "\n",
    "### 4. tp depending on location, time_of_day and day_of_week\n",
    "\n",
    "day_of_week_need_subsidy = [0,1,2,3,4] # for example, only subsidy for rush hours in weekdays\n",
    "time_index_range_in_a_week_need_subsidy = []\n",
    "for day in day_of_week_need_subsidy:\n",
    "    time_index_range_in_a_week_need_subsidy += list(arr([36,37,38,39,40]) * day)\n",
    "\n",
    "\n",
    "def t_func(t):\n",
    "    # the time state variable is an indicator for hours in week that need subsidy\n",
    "    return int(t % (48 * 7) in time_index_range_in_a_week_need_subsidy)\n",
    "range_transformed_time_index = [0, 1] # can be extended to more than two time slices\n",
    "\n",
    "location_give_subsidy = [0, 1, 2] # other regions will never receive subsidy\n",
    "\n",
    "# adaptive_tp_dictionary is a len-N of len-N_range_transformed_time_index of binary value indicating \n",
    "# whether or not this space-time slice should receive subsidy\n",
    "# For example: \n",
    "\n",
    "adaptive_action_list = []\n",
    "adaptive_tp_dictionary = []\n",
    "for region_index in range(9):\n",
    "    region_action=[]\n",
    "    for time_index in range_transformed_time_index:\n",
    "        if(time_index == 1 and region_index in location_give_subsidy):\n",
    "            adaptive_action_list.append(1)\n",
    "            region_action.append(1)\n",
    "        else:\n",
    "            adaptive_action_list.append(0)\n",
    "            region_action.append(0)\n",
    "    adaptive_tp_dictionary.append(region_action)\n",
    "\n",
    "print(adaptive_tp_dictionary)\n",
    "\n",
    "\n",
    "pi_adaptive = []\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False, fixed_policy_i = adaptive_tp_dictionary[i]): # , fixed_policy_i = adaptive_tp_dictionary[i]\n",
    "        t = int(s[3]) # already transformed by t_func\n",
    "        if random_choose:\n",
    "            return fixed_policy_i[t]\n",
    "        else:\n",
    "            return int(a == fixed_policy_i[t])\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
