{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(u_O) =  157.3 mean(u_O) =  93.7\n",
      "O_threshold = 100\n",
      "means of Order: \n",
      "\n",
      "89.6 98.6 46.6 141.0 55.2 \n",
      "\n",
      "79.0 112.6 68.9 73.6 77.3 \n",
      "\n",
      "113.8 157.3 101.0 72.1 113.5 \n",
      "\n",
      "85.1 99.5 129.4 81.3 100.2 \n",
      "\n",
      "78.0 96.1 106.4 75.3 91.5 \n",
      "\n",
      "target policy: \n",
      "\n",
      "0 0 0 1 0 \n",
      "\n",
      "0 1 0 0 0 \n",
      "\n",
      "1 1 1 0 1 \n",
      "\n",
      "0 0 1 0 1 \n",
      "\n",
      "0 0 1 0 0 \n",
      "\n",
      "number of reward locations:  9\n",
      "O_threshold = 101\n",
      "number of reward locations:  8\n",
      "O_threshold = 105\n",
      "number of reward locations:  7\n",
      "O_threshold = 110\n",
      "number of reward locations:  6\n",
      "here 200\n",
      "0 DONE!\n",
      "2 DONE!\n",
      "1 DONE!\n",
      "< ----- den func est in MC: DONE!  -----> \n",
      "std among MC reps: 0.0001850215785129844 0.030182201927122277\n",
      "WEIGHT estimation error (std_MC, std_est, median_diff, R2): \n",
      " [ 3.000e-02  6.400e-01  3.000e-01 -4.412e+02] \n",
      "\n",
      "std among MC reps: 0.0002523745133255857 0.03206810377027042\n",
      "WEIGHT estimation error (std_MC, std_est, median_diff, R2): \n",
      " [ 3.0000e-02  6.6000e-01  4.4000e-01 -4.1323e+02] \n",
      "\n",
      "std among MC reps: 0.00023580476413856814 0.035528176151526904\n",
      "WEIGHT estimation error (std_MC, std_est, median_diff, R2): \n",
      " [ 4.0000e-02  5.5000e-01  4.4000e-01 -2.2643e+02] \n",
      "\n",
      "std among MC reps: 0.0006687554496343145 0.08659869069391414\n",
      "WEIGHT estimation error (std_MC, std_est, median_diff, R2): \n",
      " [ 9.0000e-02  1.0900e+00  5.6000e-01 -1.4637e+02] \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-341cdbbd0fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                         \u001b[0mwith_MF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwith_MF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_NO_MARL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwith_NO_MARL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_IS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwith_IS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                      inner_parallel = inner_parallel)\n\u001b[0m",
      "\u001b[0;32m~/Google Drive/CausalMARL/Code/weight_val/main_200.py\u001b[0m in \u001b[0;36mV_DR\u001b[0;34m(data, adj_mat, tp, bp, Ts, Ta, dim_S_plus_Ts, t_func, penalty, penalty_NMF, CV_QV, w_hidden, lr, n_layer, reg_weight, is_weight_val, val_paras, batch_size, max_iteration, epsilon, inner_parallel, with_MF, with_NO_MARL, with_IS)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetOneRegionValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetOneRegionValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mVs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mVs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/CausalMARL/Code/weight_val/main_200.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetOneRegionValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetOneRegionValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mVs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mVs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/CausalMARL/Code/weight_val/main_200.py\u001b[0m in \u001b[0;36mgetOneRegionValue\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    148\u001b[0m                           \u001b[0mw_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mn_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                           spatial = False)\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mwi_NS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi_NS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mwi_NS\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwi_NS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/CausalMARL/Code/weight_val/main_200.py\u001b[0m in \u001b[0;36mgetWeight\u001b[0;34m(tuples_i, i, policy0, policy1, n_neigh, dim_S_plus_Ts, t_func, w_hidden, lr, n_layer, reg_weight, is_weight_val, batch_size, max_iteration, epsilon, spatial, mean_field)\u001b[0m\n\u001b[1;32m    333\u001b[0m                                   \u001b[0mtest_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                                   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_neigh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                                   epsilon = epsilon, spatial = spatial, mean_field = mean_field)\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0mcomputeWeight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_Session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/CausalMARL/Code/weight_val/weight.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, SASR, policy0, policy1, print_flag, batch_size, max_iteration, test_num, epsilon, only_state, n_neigh, spatial, mean_field)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate2\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msn2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_ratio2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpolicy_ratio2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m                 })\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# export openblas_num_threads=1; export OMP_NUM_THREADS=1; python simu.py\n",
    "\n",
    "from utils import * \n",
    "from weight import * \n",
    "from simu_funs import *  \n",
    "from main_200 import *\n",
    "a = now()\n",
    "\n",
    "rep_times = 96\n",
    "region_parallel = False\n",
    "full_parallel = False\n",
    "pattern_seed = 2\n",
    "sd_u_O = 25\n",
    "w_O = .5\n",
    "w_A = 1.5\n",
    "u_D = 80\n",
    "thre_range = [100, 101, 105, 110]\n",
    "\n",
    "penalty_range = [[3e-4, 1e-4, 5e-5], [3e-4, 1e-4, 5e-5]]\n",
    "with_NO_MARL = True\n",
    "with_IS = True\n",
    "with_MF = True\n",
    "n_layer = 3\n",
    "max_iteration = 5001\n",
    "Learning_rate = 5e-4\n",
    "w_hidden = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "aim = \"final_sd\"\n",
    "\n",
    "sd_R = 0\n",
    "day = 7\n",
    "results, res_real = [], []\n",
    "\n",
    "\n",
    "l = 5\n",
    "\n",
    "npseed(pattern_seed)\n",
    "u_O = rnorm(100, sd_u_O, l**2) \n",
    "\n",
    "\n",
    "print(\"max(u_O) = \", np.round(max(u_O), 1), \"mean(u_O) = \", np.round(np.mean(u_O), 1))\n",
    "\n",
    "# generate the corresponding target plicy\n",
    "target_policys = []\n",
    "n_tp = len(thre_range)\n",
    "for i in range(n_tp):\n",
    "    O_thre = thre_range[i]\n",
    "    print(\"O_threshold = \" + str(thre_range[i]))\n",
    "    if i == 0: \n",
    "        target_policy = simu_target_policy_pattern(l = l, u_O = u_O, threshold =  O_thre, print_flag = \"all\") # \"all\"\n",
    "    else:\n",
    "        target_policy = simu_target_policy_pattern(l = l, u_O = u_O, threshold =  O_thre, print_flag = \"None\") # \"policy_only\"\n",
    "    target_policys.append(target_policy)\n",
    "\n",
    "# generate the adj for the grid\n",
    "neigh = adj2neigh(getAdjGrid(l))\n",
    "\n",
    "\n",
    "seed = 1 \n",
    "l = 5\n",
    "T = day * 48\n",
    "t_func = None\n",
    "sd_D = None\n",
    "sd_O = None\n",
    "inner_parallel = False\n",
    "CV_QV = True\n",
    "penalty_NMF = [[1e-3], [1e-3]]\n",
    "dim_S_plus_Ts = 3 + 3\n",
    "epsilon = 1e-6\n",
    "\n",
    "##########################################################################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Output: a len-n-target of len-est results\n",
    "\"\"\"\n",
    "npseed(seed)\n",
    "N = l ** 2\n",
    "def behav(s, a):\n",
    "    return 0.5\n",
    "behav = list(itertools.repeat(behav, N))\n",
    "\n",
    "def Ts(S_neigh):\n",
    "    return np.mean(S_neigh, 0)\n",
    "def Ta(A_neigh):\n",
    "    return Ta_disc(np.mean(A_neigh, 0))\n",
    "\n",
    "# observed data following behav\n",
    "data, adj_mat, details = DG_once(seed = seed, l = l, T = T, u_D = u_D, \n",
    "                                 u_O = u_O, \n",
    "                                 t_func = t_func,  \n",
    "                                 sd_D = sd_D, sd_R = sd_R, sd_O = sd_O, \n",
    "                                 w_A = w_A, w_O = w_O)\n",
    "\n",
    "target_policy = target_policys[0]\n",
    "\n",
    "val_paras = [sd_D, sd_R, u_D, sd_O, w_A, w_O, u_O]\n",
    "\n",
    "# OPE\n",
    "a = now()\n",
    "value_targets = []\n",
    "count = 0\n",
    "n_target = len(target_policys)\n",
    "value_estimators = V_DR(data = data, tp = target_policy, bp = behav, \n",
    "                        adj_mat = adj_mat, dim_S_plus_Ts = dim_S_plus_Ts, \n",
    "                     t_func = t_func, \n",
    "                        is_weight_val = True, val_paras = val_paras, \n",
    "                     Ts = Ts, Ta = Ta, penalty = penalty_range, penalty_NMF = penalty_NMF, \n",
    "                        n_layer = n_layer, CV_QV = CV_QV, \n",
    "                    w_hidden = w_hidden, lr = Learning_rate,  \n",
    "                    batch_size = batch_size, max_iteration = max_iteration, epsilon = epsilon, \n",
    "                        with_MF = with_MF, with_NO_MARL = with_NO_MARL, with_IS = with_IS, \n",
    "                     inner_parallel = inner_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _utility import * \n",
    "from weight import * \n",
    "from simu_funs import *  \n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample input for specifying t_func and tp:\n",
    "\n",
    "### 1. tp depending on order and driver\n",
    "\n",
    "# assume s = [o, d, mismatch]r\n",
    "pi_adaptive = []\n",
    "threshold = 1\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False):\n",
    "        is_reward = int(s[0] / s[1] > threshold) # when order > driver, we give subsidy\n",
    "        if random_choose:\n",
    "            return is_reward\n",
    "        else:\n",
    "            return int(a == is_reward)\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive\n",
    "\n",
    "t_func = None\n",
    "\n",
    "### 2. tp depending on location and time_of_day - option 1 \n",
    "# (RECOMMENDED) it may reduce variance with such a discretized time stamp\n",
    "\n",
    "# if you need a more complex dependecy on time and location, please modify this exmaple or let me know\n",
    "\n",
    "def t_func(t):\n",
    "    # the time state variable is an indicator for rush hours\n",
    "    return int(t % 48 in [36,37,38,39,40])\n",
    "range_transformed_time_index = [0, 1] # can be extended to more than two time slices\n",
    "\n",
    "location_give_subsidy = [0, 1, 2] # other regions will never receive subsidy\n",
    "\n",
    "# adaptive_tp_dictionary is a len-N of len-N_range_transformed_time_index of binary value indicating \n",
    "# whether or not this space-time slice should receive subsidy\n",
    "# For example: \n",
    "\n",
    "adaptive_action_list = []\n",
    "adaptive_tp_dictionary = []\n",
    "for region_index in range(9):\n",
    "    region_action=[]\n",
    "    for time_index in range_transformed_time_index:\n",
    "        if(time_index == 1 and region_index in location_give_subsidy):\n",
    "            adaptive_action_list.append(1)\n",
    "            region_action.append(1)\n",
    "        else:\n",
    "            adaptive_action_list.append(0)\n",
    "            region_action.append(0)\n",
    "    adaptive_tp_dictionary.append(region_action)\n",
    "print(adaptive_tp_dictionary)\n",
    "\n",
    "\n",
    "pi_adaptive = []\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False, fixed_policy_i = adaptive_tp_dictionary[i]): # , fixed_policy_i = adaptive_tp_dictionary[i]\n",
    "        t = int(s[3]) # already transformed by t_func\n",
    "        if random_choose:\n",
    "            return fixed_policy_i[t]\n",
    "        else:\n",
    "            return int(a == fixed_policy_i[t])\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive\n",
    "\n",
    "\n",
    "### 3. tp depending on location and time_of_day - option 2\n",
    "def t_func(t):\n",
    "    return int(t % 48)\n",
    "\n",
    "adaptive_action_list = []\n",
    "adaptive_tp_dictionary = []\n",
    "for region_index in range(9):\n",
    "    region_action=[]\n",
    "    for time_index in range(336):\n",
    "        if(time_index%48 in [36,37,38,39,40]):\n",
    "            adaptive_action_list.append(1)\n",
    "            region_action.append(1)\n",
    "        else:\n",
    "            adaptive_action_list.append(0)\n",
    "            region_action.append(0)\n",
    "    adaptive_tp_dictionary.append(region_action)\n",
    "# print(adaptive_tp_dictionary)\n",
    "\n",
    "pi_adaptive = []\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False, fixed_policy_i = adaptive_tp_dictionary[i]):\n",
    "        t = int(s[3])\n",
    "        if random_choose:\n",
    "            return fixed_policy_i[t]\n",
    "        else:\n",
    "            return int(a == fixed_policy_i[t])\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive\n",
    "\n",
    "\n",
    "### 4. tp depending on location, time_of_day and day_of_week\n",
    "\n",
    "day_of_week_need_subsidy = [0,1,2,3,4] # for example, only subsidy for rush hours in weekdays\n",
    "time_index_range_in_a_week_need_subsidy = []\n",
    "for day in day_of_week_need_subsidy:\n",
    "    time_index_range_in_a_week_need_subsidy += list(arr([36,37,38,39,40]) * day)\n",
    "\n",
    "\n",
    "def t_func(t):\n",
    "    # the time state variable is an indicator for hours in week that need subsidy\n",
    "    return int(t % (48 * 7) in time_index_range_in_a_week_need_subsidy)\n",
    "range_transformed_time_index = [0, 1] # can be extended to more than two time slices\n",
    "\n",
    "location_give_subsidy = [0, 1, 2] # other regions will never receive subsidy\n",
    "\n",
    "# adaptive_tp_dictionary is a len-N of len-N_range_transformed_time_index of binary value indicating \n",
    "# whether or not this space-time slice should receive subsidy\n",
    "# For example: \n",
    "\n",
    "adaptive_action_list = []\n",
    "adaptive_tp_dictionary = []\n",
    "for region_index in range(9):\n",
    "    region_action=[]\n",
    "    for time_index in range_transformed_time_index:\n",
    "        if(time_index == 1 and region_index in location_give_subsidy):\n",
    "            adaptive_action_list.append(1)\n",
    "            region_action.append(1)\n",
    "        else:\n",
    "            adaptive_action_list.append(0)\n",
    "            region_action.append(0)\n",
    "    adaptive_tp_dictionary.append(region_action)\n",
    "\n",
    "print(adaptive_tp_dictionary)\n",
    "\n",
    "\n",
    "pi_adaptive = []\n",
    "for i in range(9):\n",
    "    def tp_i(s, a = 0, random_choose = False, fixed_policy_i = adaptive_tp_dictionary[i]): # , fixed_policy_i = adaptive_tp_dictionary[i]\n",
    "        t = int(s[3]) # already transformed by t_func\n",
    "        if random_choose:\n",
    "            return fixed_policy_i[t]\n",
    "        else:\n",
    "            return int(a == fixed_policy_i[t])\n",
    "    pi_adaptive.append(tp_i)\n",
    "target_policy = pi_adaptive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
